{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6a6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6172c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_data = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5556a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitWeightNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InitWeightNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.constant_(self.output.weight, 0.01)\n",
    "        \n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        nn.init.zeros_(self.output.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41747f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InitWeightNet()\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeffcfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1530\n",
      "Epoch 2, Loss: 0.0475\n",
      "Epoch 3, Loss: 0.0233\n",
      "Epoch 4, Loss: 0.0666\n",
      "Epoch 5, Loss: 0.0626\n",
      "Epoch 6, Loss: 0.1319\n",
      "Epoch 7, Loss: 0.0161\n",
      "Epoch 8, Loss: 0.0065\n",
      "Epoch 9, Loss: 0.0712\n",
      "Epoch 10, Loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "e = []\n",
    "l = []\n",
    "for epoch in range(10):\n",
    "    for images, labels in train_loader:\n",
    "        # print(labels)\n",
    "        \n",
    "        outputs = model(images) # predict : Forward pass\n",
    "        # print(outputs)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        \n",
    "        optimizer.zero_grad() # clear previous gradients\n",
    "        loss.backward() # backpropagation: compute gradients\n",
    "        optimizer.step() # update weights using gradients\n",
    "\n",
    "    e.append(epoch)\n",
    "    l.append(loss.item())\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
